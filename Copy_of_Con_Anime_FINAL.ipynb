{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Con Anime FINAL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMgH+4FRQgHUXr2NKWsCdzz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/projectgroup2110/Stock-Sentiment-Analysis-NLP-project/blob/master/Copy_of_Con_Anime_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCQoUI7dNY7t",
        "colab_type": "code",
        "outputId": "740becf7-e0c9-4416-bc78-70c2f1627e6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "!git clone -l -s https://github.com/projectgroup2110/BEProjectGanAnime.git cloned-repo"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cloned-repo'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 24 (delta 8), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (24/24), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkw8IBIgAK_z",
        "colab_type": "code",
        "outputId": "5806bd6d-3a69-49a1-eac8-aeb2c40089af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KggW1UKdAOYs",
        "colab_type": "code",
        "outputId": "d2ff216a-711a-4db6-cdda-7dbceb56b2e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/cloned-repo/src"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/cloned-repo/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eFEL18zAQ5N",
        "colab_type": "code",
        "outputId": "c90d8275-2348-47e7-e751-ffedcda826d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH4IeGp0BtLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "# from google.colab import auth\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# # Authenticate and create the PyDrive client.\n",
        "# # This only needs to be done once per notebook.\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKE9sZCACZO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "# file_id = '19SaalG6mDQwiBFMVApcap58ob-t3mznU'\n",
        "# downloaded = drive.CreateFile({'id': file_id})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUDFLVyYEW2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp /content/drive/My\\ Drive/datasets/ACGAN_generator.ckpt /content/cloned-repo/src/mymodel/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZkmS-bsGHK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 test.py -t fix_hair_eye --hair purple --eye red -d /content/cloned-repo/src/mymodel/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcB6PJ-W35CP",
        "colab_type": "code",
        "outputId": "b8f4ac59-592f-4630-a7a0-1e0c1ca9c6f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "!pip install anvil-uplink"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting anvil-uplink\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/5c/6674e25d83936fdf162826d2a9173c831f6c706fdcb30b1aa3b1e0632dcd/anvil_uplink-0.3.29-py2.py3-none-any.whl (53kB)\n",
            "\r\u001b[K     |██████▏                         | 10kB 25.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 20kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 40kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 51kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from anvil-uplink) (1.12.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from anvil-uplink) (0.16.0)\n",
            "Collecting argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Collecting ws4py==0.3.4\n",
            "  Downloading https://files.pythonhosted.org/packages/aa/60/5d135c8161a2a67d7c227d57bb599fad967d818dbcdca08daa2d60eb87b9/ws4py-0.3.4.tar.gz\n",
            "Building wheels for collected packages: ws4py\n",
            "  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ws4py: filename=ws4py-0.3.4-cp36-none-any.whl size=41809 sha256=4375df96d5a4048b97275595b15100856cdb7ff09581ca105bbd112f1c6df51b\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/1f/0d/beff5822af761b66067b5e0b251a9c66af3ae15828ee9a8f15\n",
            "Successfully built ws4py\n",
            "Installing collected packages: argparse, ws4py, anvil-uplink\n",
            "Successfully installed anvil-uplink-0.3.29 argparse-1.4.0 ws4py-0.3.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dl4Q1rd3_tP",
        "colab_type": "code",
        "outputId": "77bc655b-3326-4bb8-fd7b-3789af161c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import anvil.server\n",
        "anvil.server.connect('QHZWYIO4L5CHOLFY4XR6TS7D-OYWK4Q5T4YWKQLN2')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Connecting to wss://anvil.works/uplink\n",
            "Anvil websocket open\n",
            "Authenticated OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb4c97bI7X_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as Transform\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import datasets\n",
        "import ACGAN\n",
        "import utils\n",
        "\n",
        "import folium\n",
        "from folium import plugins\n",
        "from PIL import Image\n",
        "\n",
        "import anvil.media\n",
        "\n",
        "# from argparse import ArgumentParser\n",
        "\n",
        "hair_mapping =  ['orange', 'white', 'aqua', 'gray', 'green', 'red', 'purple', \n",
        "                 'pink', 'blue', 'black', 'brown', 'blonde']\n",
        "hair_dict = {\n",
        "    'orange' : 0,\n",
        "    'white': 1, \n",
        "    'aqua': 2,\n",
        "    'gray': 3,\n",
        "    'green': 4,\n",
        "    'red': 5,\n",
        "    'purple': 6,\n",
        "    'pink': 7,\n",
        "    'blue': 8,\n",
        "    'black': 9,\n",
        "    'brown': 10,\n",
        "    'blonde': 11\n",
        "}\n",
        "\n",
        "eye_mapping = ['black', 'orange', 'pink', 'yellow', 'aqua', 'purple', 'green', \n",
        "               'brown', 'red', 'blue']\n",
        "eye_dict = {\n",
        "    'black': 0,\n",
        "    'orange': 1,\n",
        "    'pink': 2,\n",
        "    'yellow': 3,\n",
        "    'aqua' : 4,\n",
        "    'purple': 5,\n",
        "    'green': 6,\n",
        "    'brown': 7,\n",
        "    'red': 8,\n",
        "    'blue': 9\n",
        "}\n",
        "\n",
        "\n",
        "# parser = ArgumentParser()\n",
        "# parser.add_argument('-t', '--type', help = 'Type of anime generation.', \n",
        "#                     choices = ['fix_noise', 'fix_hair_eye', 'change_hair', 'change_eye', 'interpolate'], \n",
        "#                     default = 'fix_noise', type = str)\n",
        "# parser.add_argument('--hair', help = 'Determine the hair color of the anime characters.', \n",
        "#                     default = None, choices = hair_mapping, type = str)\n",
        "# parser.add_argument('--eye',  help = 'Determine the eye color of the anime characters.',\n",
        "#                     default = None, choices = eye_mapping, type = str)\n",
        "# parser.add_argument('-s', '--sample_dir', help = 'Folder to save the generated samples.',\n",
        "#                     default = '../generated', type = str)\n",
        "# parser.add_argument('-d', '--model_dir', help = 'Folder where the trained model is saved',\n",
        "#                     default = '../models', type = str)\n",
        "# args = parser.parse_args()\n",
        "\n",
        "def generate_by_attributes(model, device, latent_dim, hair_classes, eye_classes, hair_color, eye_color):\n",
        "    hair_tag = torch.zeros(64, hair_classes).to(device)\n",
        "    eye_tag = torch.zeros(64, eye_classes).to(device)\n",
        "    hair_class = hair_dict[hair_color]\n",
        "    eye_class = eye_dict[eye_color]\n",
        "    for i in range(64):\n",
        "        hair_tag[i][hair_class], eye_tag[i][eye_class] = 1, 1\n",
        "    \n",
        "    tag = torch.cat((hair_tag, eye_tag), 1)\n",
        "    z = torch.randn(64, latent_dim).to(device)\n",
        "    \n",
        "    output = model(z, tag)\n",
        "    #save_image(utils.denorm(output), '{}/{} hair {} eyes.png'.format(args.sample_dir, hair_mapping[hair_class], eye_mapping[eye_class]))\n",
        "    save_image(utils.denorm(output), '{}/{} hair {} eyes.png'.format('../generated', hair_mapping[hair_class], eye_mapping[eye_class]))\n",
        "    ##save_image(utils.denorm(output), '{}/{} hair {} eyes.jpg'.format('../generated', hair_mapping[hair_class], eye_mapping[eye_class]))\n",
        "\n",
        "    #utils.denorm(output)\n",
        "\n",
        "    #return output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@anvil.server.callable   \n",
        "def main(hair,eye):\n",
        "    # if not os.path.exists(args.sample_dir):\n",
        "    #     os.mkdir(args.sample_dir)\n",
        "    if not os.path.exists('../generated'):\n",
        "        os.mkdir('../generated')\n",
        "    latent_dim = 100\n",
        "    hair_classes = 12\n",
        "    eye_classes = 10\n",
        "    batch_size = 1\n",
        "\n",
        "    device = 'cpu'\n",
        "   # G_path = '{}/ACGAN_generator.ckpt'.format(args.model_dir)\n",
        "    G_path = '/content/cloned-repo/src/mymodel/ACGAN_generator.ckpt'\n",
        "\n",
        "    G = G = ACGAN.Generator(latent_dim = latent_dim, class_dim = hair_classes + eye_classes)\n",
        "    prev_state = torch.load(G_path)\n",
        "    G.load_state_dict(prev_state['model'])\n",
        "    G = G.eval()\n",
        "\n",
        "    # if args.type == 'fix_hair_eye':\n",
        "    #     generate_by_attributes(G, device, latent_dim, hair_classes, eye_classes, args.hair,  args.eye)\n",
        "    # elif args.type == 'change_eye':\n",
        "    #     eye_grad(G, device, latent_dim, hair_classes, eye_classes)\n",
        "    # elif args.type == 'change_hair':\n",
        "    #     hair_grad(G, device, latent_dim, hair_classes, eye_classes)\n",
        "    # elif args.type == 'interpolate':\n",
        "    #     interpolate(G, device, latent_dim, hair_classes, eye_classes)\n",
        "    # else:\n",
        "    #     fix_noise(G, device, latent_dim, hair_classes, eye_classes)\n",
        "\n",
        "    generate_by_attributes(G, device, latent_dim, hair_classes, eye_classes, hair,  eye)\n",
        "\n",
        "    # result_image = Image.open('/content/cloned-repo/generated/{} hair {} eyes.png'.format(hair,eye))  \n",
        "    # return result_image\n",
        "    return(anvil.media.from_file('/content/cloned-repo/generated/{} hair {} eyes.png'.format(hair,eye)))\n",
        "    \n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX1ro_21CdrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}